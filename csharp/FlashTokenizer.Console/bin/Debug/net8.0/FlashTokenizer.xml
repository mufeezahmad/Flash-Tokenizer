<?xml version="1.0"?>
<doc>
    <assembly>
        <name>FlashTokenizer</name>
    </assembly>
    <members>
        <member name="T:FlashTokenizer.BasicTokenizer">
            <summary>
            Basic text preprocessing for BERT: cleaning, whitespace splitting, Chinese char spacing, punctuation split.
            </summary>
        </member>
        <member name="T:FlashTokenizer.BpeTokenizer">
            <summary>
            GPT-2 style Byte Pair Encoding (byte-level) tokenizer with regex pre-tokenization.
            </summary>
        </member>
        <member name="M:FlashTokenizer.BpeTokenizer.#ctor(System.String,System.String)">
            <summary>
            Create BPE tokenizer from vocab.json and merges.txt.
            </summary>
        </member>
        <member name="M:FlashTokenizer.BpeTokenizer.Encode(System.String)">
            <inheritdoc />
        </member>
        <member name="M:FlashTokenizer.BpeTokenizer.Decode(System.Collections.Generic.IEnumerable{System.Int32})">
            <inheritdoc />
        </member>
        <member name="T:FlashTokenizer.FlashBertTokenizer">
            <summary>
            High-performance BERT WordPiece tokenizer (forward direction).
            </summary>
        </member>
        <member name="M:FlashTokenizer.FlashBertTokenizer.Encode(System.String,System.String,System.Int32)">
            <summary>
            Encode input text to token ids with optional padding and max length.
            </summary>
            <param name="text">Input text.</param>
            <param name="padding">Padding mode: "max_length" or other.</param>
            <param name="maxLength">Max length; -1 uses model default.</param>
        </member>
        <member name="M:FlashTokenizer.FlashBertTokenizer.Decode(System.Collections.Generic.IEnumerable{System.Int32})">
            <summary>
            Decode token ids to a readable string (merging WordPiece prefixes).
            </summary>
        </member>
        <member name="T:FlashTokenizer.FlashTokenizer">
            <summary>
            Public facade for WordPiece/BERT tokenization, ready for app consumption.
            </summary>
        </member>
        <member name="M:FlashTokenizer.FlashTokenizer.#ctor(System.String,System.Boolean,System.Int32,System.Boolean)">
            <summary>
            Create a tokenizer using provided options.
            </summary>
            <param name="vocabPath">Path to vocab.txt. If null, defaults to sample/vocab.txt.</param>
            <param name="doLowerCase">Lowercase and strip accents.</param>
            <param name="modelMaxLength">Max length; -1 for unlimited.</param>
            <param name="enableBidirectional">Enable bidirectional fallback heuristic.</param>
        </member>
        <member name="M:FlashTokenizer.FlashTokenizer.#ctor(FlashTokenizer.TokenizerOptions)">
            <summary>
            Create a tokenizer using a TokenizerOptions object.
            </summary>
        </member>
        <member name="M:FlashTokenizer.FlashTokenizer.Encode(System.String,System.String,System.Int32)">
            <inheritdoc />
        </member>
        <member name="M:FlashTokenizer.FlashTokenizer.Decode(System.Collections.Generic.IEnumerable{System.Int32})">
            <inheritdoc />
        </member>
        <member name="T:FlashTokenizer.ITokenizer">
            <summary>
            Simple tokenizer abstraction to support multiple algorithms (e.g., WordPiece, BPE).
            </summary>
        </member>
        <member name="M:FlashTokenizer.ITokenizer.Encode(System.String)">
            <summary>
            Encode input text to token ids.
            </summary>
            <param name="input">Text to tokenize.</param>
            <returns>List of token ids.</returns>
        </member>
        <member name="M:FlashTokenizer.ITokenizer.Decode(System.Collections.Generic.IEnumerable{System.Int32})">
            <summary>
            Decode token ids back to text.
            </summary>
            <param name="ids">Token ids to decode.</param>
            <returns>Decoded text.</returns>
        </member>
        <member name="T:FlashTokenizer.TokenizerOptions">
            <summary>
            Options for configuring the tokenizer behavior.
            </summary>
        </member>
        <member name="P:FlashTokenizer.TokenizerOptions.VocabPath">
            <summary>
            Path to vocab.txt (BERT WordPiece) or equivalent file.
            </summary>
        </member>
        <member name="P:FlashTokenizer.TokenizerOptions.DoLowerCase">
            <summary>
            Whether to lowercase and strip accents (as in original BERT-uncased).
            </summary>
        </member>
        <member name="P:FlashTokenizer.TokenizerOptions.ModelMaxLength">
            <summary>
            Maximum sequence length; -1 means unlimited.
            </summary>
        </member>
        <member name="P:FlashTokenizer.TokenizerOptions.EnableBidirectional">
            <summary>
            Use bidirectional WordPiece fallback heuristic.
            </summary>
        </member>
        <member name="P:FlashTokenizer.TokenizerOptions.Type">
            <summary>
            Select tokenizer algorithm. Default: Bert.
            </summary>
        </member>
        <member name="P:FlashTokenizer.TokenizerOptions.BpeVocabJsonPath">
            <summary>
            Path to BPE vocab.json (for GPT-2 style BPE).
            </summary>
        </member>
        <member name="P:FlashTokenizer.TokenizerOptions.BpeMergesPath">
            <summary>
            Path to BPE merges.txt (for GPT-2 style BPE).
            </summary>
        </member>
        <member name="T:FlashTokenizer.TokenizerType">
            <summary>
            Tokenizer algorithm selection.
            </summary>
        </member>
        <member name="F:FlashTokenizer.TokenizerType.Bert">
            <summary>BERT WordPiece tokenizer.</summary>
        </member>
        <member name="F:FlashTokenizer.TokenizerType.BPE">
            <summary>GPT-2 style BPE tokenizer.</summary>
        </member>
        <member name="T:FlashTokenizer.WordpieceTokenizer">
            <summary>
            WordPiece tokenizer core using initial and suffix tries for fast matching.
            </summary>
        </member>
    </members>
</doc>
